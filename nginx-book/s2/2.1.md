# 初探 nginx 架构
***

&emsp;&emsp;
众所周知，nginx 性能高，而 nginx 的高性能与其架构是分不开的。
那么 nginx 究竟是怎么样的呢？这一节我们先来初识一下 nginx 框架吧。

&emsp;&emsp;
nginx在启动后，在 unix 系统中会以 daemon 的方式在后台运行，后台进程包含一个 master 进程和多个 worker 进程。
我们也可以手动地关掉后台模式，让 nginx 在前台运行，并且通过配置让 nginx 取消 master 进程，从而可以使 nginx 以单进程方式运行。
很显然生产环境下我们肯定不会这么做，所以关闭后台模式一般是用来调试用的，在后面的章节里面，我们会详细地讲解如何调试 nginx。
所以我们可以看到，nginx 是以多进程的方式来工作的，当然 nginx 也是支持多线程的方式的，只是我们主流的方式还是多进程的方式，也是 nginx 的默认方式。
nginx 采用多进程的方式有诸多好处，所以就主要讲解 nginx 的多进程模式吧。

&emsp;&emsp;
刚才讲到，nginx 在启动后，会有一个 master 进程和多个 worker 进程。
master 进程主要用来管理 worker 进程，包含：接收来自外界的信号，向各 worker 进程发送信号，监控 worker 进程的运行状态，当 worker 进程退出后(异常情况下)，会自动重新启动新的 worker 进程。
而基本的网络事件，则是放在 worker 进程中来处理了。
多个 worker 进程之间是对等的，他们同等竞争来自客户端的请求，各进程互相之间是独立的。
一个请求只可能在一个 worker 进程中处理，一个 worker 进程，不可能处理其它进程的请求。
worker 进程的个数是可以设置的，一般我们会设置与机器 cpu 核数一致，这里面的原因与 nginx 的进程模型以及事件处理模型是分不开的。
nginx 的进程模型，可以由下图来表示：

![image](/images/2.1/01.png)

&emsp;&emsp;
在 nginx 启动后，如果要操作 nginx，要怎么做呢？
从上文中可以看到，master 来管理 worker 进程，所以只需要与 master 进程通信就行了。
master 进程会接收来自外界发来的信号，再根据信号做不同的事情。
所以要控制 nginx，只需要通过 kill 向 master 进程发送信号就行了。
比如 kill -HUP pid，则是告诉 nginx，从容地重启 nginx，我们一般用这个信号来重启nginx，或重新加载配置，因为是从容地重启，因此服务是不中断的。
master 进程在接收到 HUP 信号后是怎么做的呢？
首先 master 进程在接到信号后，会先重新加载配置文件，然后再启动新的 worker 进程，并向所有老的 worker 进程发送信号，告诉他们可以光荣退休了。
新的 worker 在启动后，就开始接收新的请求，而老的 worker 在收到来自 master 的信号后，就不再接收新的请求，并且在当前进程中的所有未处理完的请求处理完成后再退出。
当然直接给 master 进程发送信号，这是比较老的操作方式，nginx 在 0.8 版本之后，引入了一系列命令行参数来方便管理。
比如 ./nginx -s reload 就是来重启 nginx，./nginx -s stop，就是来停止nginx的运行。
如何做到的呢？
我们还是拿 reload 来说，当执行命令时，是启动一个新的 nginx 进程，而新的 nginx 进程在解析到 reload 参数后，就知道我们的目的是控制 nginx 来重新加载配置文件了，它会向 master 进程发送信号，然后接下来的动作，就和直接向 master 进程发送信号一样了。

&emsp;&emsp;
现在我们知道了当操作 nginx 的时候 nginx 内部做了些什么事情，那么 worker 进程又是如何处理请求的呢？
前面有提到 worker 进程之间是平等的，每个进程处理请求的机会也是一样的。
当提供 80 端口的 http 服务时，一个连接请求过来，每个进程都有可能处理这个连接，怎么做到的呢？
首先每个 worker 进程都是从 master 进程 fork 过来，在 master 进程里面，先建立好需要 listen 的 socket（listenfd）之后，再 fork 出多个 worker 进程。
所有 worker 进程的 listenfd 会在新连接到来时变得可读，为保证只有一个进程处理该连接，所有 worker 进程在注册 listenfd 读事件前抢 accept_mutex，抢到互斥锁的那个进程注册 listenfd 读事件，在读事件里调用 accept 接受该连接。
当一个 worker 进程在 accept 这个连接之后，就开始读取请求，解析请求，处理请求，产生数据后，再返回给客户端，最后才断开连接，一个完整的请求就是这样的了。
可以看到，一个请求完全由 worker 进程来处理，而且只在一个 worker 进程中处理。

&emsp;&emsp;
那么 nginx 采用这种进程模型有什么好处呢？
首先对于每个 worker 进程来说，独立的进程不需要加锁，所以省掉了锁带来的开销，同时在编程以及问题查找时，也会方便很多。
其次采用独立的进程，可以让互相之间不会影响，一个进程退出后，其它进程还在工作，服务不会中断，master 进程则很快启动新的 worker 进程。
当然 worker 进程的异常退出，肯定是程序有 bug 了，异常退出，会导致当前 worker 上的所有请求失败，不过不会影响到所有请求，所以降低了风险。
当然，好处还有很多，大家可以慢慢体会。

&emsp;&emsp;
上面讲了很多关于nginx的进程模型，接下来，我们来看看 nginx 是如何处理事件的。

&emsp;&emsp;
有人可能要问了，nginx 采用多 worker 的方式来处理请求，每个 worker 里面只有一个主线程，那能够处理的并发数很有限啊，多少个 worker 就能处理多少个并发，何来高并发呢？
非也，这就是 nginx 的高明之处，nginx 采用了异步非阻塞的方式来处理请求，也就是说，nginx 是可以同时处理成千上万个请求的。
想想 apache 的常用工作方式（apache 也有异步非阻塞版本，但因其与自带某些模块冲突，所以不常用），每个请求会独占一个工作线程，当并发数上到几千时，就同时有几千的线程在处理请求了。
这对操作系统来说是个不小的挑战，线程带来的内存占用非常大，线程的上下文切换带来的cpu开销很大，自然性能就上不去了，而这些开销完全是没有意义的。

&emsp;&emsp;
为什么 nginx 可以采用异步非阻塞的方式来处理呢，或者异步非阻塞到底是怎么回事呢？
我们先回到原点，看看一个请求的完整过程。
首先请求过来，要建立连接，然后再接收数据，接收数据后，再发送数据。
具体到系统底层，就是读写事件，而当读写事件没有准备好时，必然不可操作，如果不用非阻塞的方式来调用，那就得阻塞调用了，事件没有准备好，那就只能等了，等事件准备好了，你再继续吧。
阻塞调用会进入内核等待，cpu 就会让出去给别人用了，对单线程的 worker 来说显然不合适，当网络事件越多时，大家都在等待呢，cpu 空闲下来没人用，cpu 利用率自然上不去了，更别谈高并发了。
好吧，你说加进程数，这跟 apache 的线程模型有什么区别，注意，别增加无谓的上下文切换。
所以在 nginx 里面，最忌讳阻塞的系统调用了。
不要阻塞，那就非阻塞喽。
非阻塞就是，事件没有准备好，马上返回 EAGAIN，告诉你事件还没准备好呢，你慌什么，过会再来吧。
好吧，你过一会再来检查一下事件，直到事件准备好了为止，在这期间，你就可以先去做其它事情，然后再来看看事件好了没。

&emsp;&emsp;
虽然不阻塞了，但还得不时地过来检查一下事件的状态，就可以做更多的事情了，但带来的开销也是不小的。
所以才会有了异步非阻塞的事件处理机制，具体到系统调用就是像 select/poll/epoll/kqueue 这样的系统调用。
它们提供了一种机制，可以同时监控多个事件，调用他们是阻塞的，但可以设置超时时间，在超时时间之内，如果有事件准备好了就返回。
这种机制正好解决了上面的两个问题，拿 epoll 为例(在后面的例子中，我们多以 epoll 为例子，以代表这一类函数)，当事件没准备好时，放到 epoll 里面，事件准备好了就去读写，当读写返回 EAGAIN 时，将它再次加入到 epoll 里面。这样只要有事件准备好了就去处理它，只有当所有事件都没准备好时，才在 epoll 里面等着。
这样就可以并发处理大量的并发了，当然这里的并发请求是指未处理完的请求，线程只有一个，所以同时能处理的请求当然只有一个了，只是在请求间进行不断地切换而已，切换也是因为异步事件未准备好而主动让出的。
这里的切换是没有任何代价，可以理解为循环处理多个准备好的事件，事实上就是这样的。

&emsp;&emsp;
之前说过，推荐设置 worker 的个数为 cpu 的核数，在这里就很容易理解了，更多的 worker 数，只会导致进程来竞争 cpu 资源，从而带来不必要的上下文切换。
而且 nginx 为了更好的利用多核特性，提供了 cpu 亲缘性的绑定选项，可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来 cache 的失效。
像这种小的优化在 nginx 中非常常见，同时也说明了 nginx 作者的苦心孤诣。
比如 nginx 在做 4 个字节的字符串比较时，会将 4 个字符转换成一个 int 型再作比较，以减少 cpu 的指令数等等。

&emsp;&emsp;
现在知道了 nginx 为什么会选择这样的进程模型与事件模型了。
对于一个基本的 web 服务器来说，事件通常有三种类型：网络事件、信号、定时器。
从上面的讲解中知道，网络事件通过异步非阻塞可以很好的解决掉。
如何处理信号与定时器？

&emsp;&emsp;
首先信号的处理。
对 nginx 来说，有一些特定的信号代表着特定的意义。
信号会中断掉程序当前的运行，在改变状态后，继续执行。
如果是系统调用，则可能会导致系统调用的失败，需要重入。
关于信号的处理，大家可以学习一些专业书籍，这里不多说。
对于 nginx 来说，如果 nginx 正在等待事件（epoll_wait 时），如果程序收到信号，在信号处理函数处理完后，epoll_wait 会返回错误，然后程序可再次进入 epoll_wait 调用。

&emsp;&emsp;
另外再来看看定时器。
由于 epoll_wait 等函数在调用的时候是可以设置一个超时时间的，所以 nginx 借助这个超时时间来实现定时器。
nginx 里面的定时器事件是放在一颗维护定时器的红黑树里面，每次在进入 epoll_wait 前，先从该红黑树里面拿到所有定时器事件的最小时间，在计算出 epoll_wait 的超时时间后进入 epoll_wait。
所以当没有事件产生也没有中断信号时，epoll_wait 会超时，也就是说定时器事件到了。
这时 nginx 会检查所有的超时事件，将他们的状态设置为超时，然后再去处理网络事件。
由此可以看出，当我们写 nginx 代码时，在处理网络事件的回调函数时，通常做的第一个事情就是判断超时，然后再去处理网络事件。

&emsp;&emsp;
我们可以用一段伪代码来总结一下nginx的事件处理模型：

    while (true) {
        for t in run_tasks:
            t.handler();
        update_time(&now);
        timeout = ETERNITY;
        for t in wait_tasks: /* sorted already */
            if (t.time <= now) {
                t.timeout_handler();
            } else {
                timeout = t.time - now;
                break;
            }
        nevents = poll_function(events, timeout);
        for i in nevents:
            task t;
            if (events[i].type == READ) {
                t.handler = read_handler;
            } else { /* events[i].type == WRITE */
                t.handler = write_handler;
            }
            run_tasks_add(t);
    }

&emsp;&emsp;
好，本节我们讲了进程模型，事件模型，包括网络事件，信号，定时器事件。